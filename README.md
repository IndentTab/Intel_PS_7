# Visual Search using VLM
We used CLIP to generate image and text embeddings and FAISS to search through a dataset of 50k images to provide visual search.

## Running
Run `Gradio.ipynb`. It fetches the datasets using drive links and downloads the required models so it can be run standalone. If you want to use your own datasets, change the constants pointing to where the images are stored. Note, `IMAGE_FOLDER_PATH` also needs to be updated after the images have been extracted.

## Datasets
Two datasets are required for this project. DSD 50k is a collected of the first 50000 images from [this](https://huggingface.co/datasets/primecai/dsd_data) dataset of AI generated images named by their index for convenience. DSD Embeddings are the image embeddings of those images and text embeddings of their description also as generated by CLIP.

DSD 50k: https://www.kaggle.com/datasets/meltqx/dsd-50k/data

DSD Embeddings: https://www.kaggle.com/datasets/meltqx/primecai

If using DSD 50k, disable the initial code to download and extract the zip file contain the images in the ipynb file.

## Demo





https://github.com/user-attachments/assets/4d4d1299-4dd2-4c8d-a778-1949f90eba7e

